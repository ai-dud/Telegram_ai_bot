import os
import tempfile
import time
from datetime import datetime
import speech_recognition as sr
from pydub import AudioSegment
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters
import google.generativeai as genai
import requests
from dotenv import load_dotenv

# Load environment variables
load_dotenv()
TELEGRAM_TOKEN = os.getenv('TELEGRAM_TOKEN')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
ELEVENLABS_API_KEY = os.getenv('ELEVENLABS_API_KEY')

# Initialize Gemini AI
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-pro')

# Create temp directory
TEMP_DIR = "temp"
if not os.path.exists(TEMP_DIR):
    os.makedirs(TEMP_DIR)

async def start(update: Update, context):
    welcome_message = """
ЁЯдЦ *AI Voice Bot рдореЗрдВ рдЖрдкрдХрд╛ рд╕реНрд╡рд╛рдЧрдд рд╣реИ!*
рдореБрдЭреЗ рдХреЛрдИ рднреА рд╕рд╡рд╛рд▓ рдкреВрдЫреЗрдВ, рдореИрдВ рд╣рд┐рдВрджреА рдореЗрдВ рдЬрд╡рд╛рдм рджреВрдВрдЧрд╛ред
    """
    await update.message.reply_text(welcome_message, parse_mode='Markdown')

async def generate_hindi_response(text):
    try:
        prompt = f"""
        рдЖрдк рдПрдХ рдмрд╣реБрдд рд╣реА рдХреБрд╢рд▓ рдФрд░ рдордЬрд╝реЗрджрд╛рд░ AI рд╕рд╣рд╛рдпрдХ рд╣реИрдВред рдпреВрдЬрд╝рд░ рдХреЗ рд╕рд╡рд╛рд▓ рдХрд╛ рдЬрд╡рд╛рдм рдЗрди рдирд┐рд░реНрджреЗрд╢реЛрдВ рдХреЗ рдЕрдиреБрд╕рд╛рд░ рджреЗрдВ:

        1. рдЬрд╡рд╛рдм рдХреА рд╡рд┐рд╢реЗрд╖рддрд╛рдПрдВ:
           - рдмрд┐рд▓реНрдХреБрд▓ рд╕рдЯреАрдХ рдФрд░ рддрдереНрдпрд╛рддреНрдордХ рдЬрд╛рдирдХрд╛рд░реА рджреЗрдВ
           - рд╕рд░рд▓ рдФрд░ рд░реЛрдЪрдХ рднрд╛рд╖рд╛ рдХрд╛ рдкреНрд░рдпреЛрдЧ рдХрд░реЗрдВ
           - рд╣рд░ рдЬрд╡рд╛рдм рдореЗрдВ рдПрдХ рдордЬрд╝реЗрджрд╛рд░ рдЯрд┐рдкреНрдкрдгреА рдпрд╛ рдЙрджрд╛рд╣рд░рдг рдЬреЛрдбрд╝реЗрдВ
           - рдЬрд╡рд╛рдм рдХреЛ рд╕рдВрдХреНрд╖рд┐рдкреНрдд рд▓реЗрдХрд┐рди рдкреВрд░реНрдг рд░рдЦреЗрдВ (40-50 рд╢рдмреНрдж)

        2. рдЬрд╡рд╛рдм рдХрд╛ рдкреНрд░рд╛рд░реВрдк:
           - рдкрд╣рд▓реЗ рдореБрдЦреНрдп рдЬрд╛рдирдХрд╛рд░реА рджреЗрдВ
           - рдлрд┐рд░ рдПрдХ рдордЬрд╝реЗрджрд╛рд░ рдЯрд┐рдкреНрдкрдгреА рдпрд╛ рдЙрджрд╛рд╣рд░рдг
           - рдЕрдВрдд рдореЗрдВ рдПрдХ рдЫреЛрдЯреА рд╕реА рд╕рд▓рд╛рд╣ рдпрд╛ рдирд┐рд╖реНрдХрд░реНрд╖

        3. рд╡рд┐рд╢реЗрд╖ рдзреНрдпрд╛рди:
           - рд╣рд░ рдЬрд╡рд╛рдм 100% рд╕рдЯреАрдХ рд╣реЛрдирд╛ рдЪрд╛рд╣рд┐рдП
           - рдЬрд╡рд╛рдм рд╣рд┐рдВрджреА рдореЗрдВ рд╣реА рджреЗрдВ
           - рдЬрдЯрд┐рд▓ рд╡рд┐рд╖рдпреЛрдВ рдХреЛ рднреА рд╕рд░рд▓ рдмрдирд╛рдХрд░ рд╕рдордЭрд╛рдПрдВ
           - рдпрджрд┐ рдХреЛрдИ рдмрд╛рдд рд╕реНрдкрд╖реНрдЯ рдирд╣реАрдВ рд╣реИ, рддреЛ рд╕реНрдкрд╖реНрдЯреАрдХрд░рдг рдорд╛рдВрдЧреЗрдВ

        рдЙрджрд╛рд╣рд░рдг рдЬрд╡рд╛рдм:
        "рд╕реВрд░реНрдп рд╕реЗ рдкреГрдереНрд╡реА рдХреА рджреВрд░реА 15 рдХрд░реЛрдбрд╝ рдХрд┐рд▓реЛрдореАрдЯрд░ рд╣реИред рдЗрддрдиреА рджреВрд░реА рддреЛ рдореЗрд░реЗ рдкрдбрд╝реЛрд╕реА рдХреА рдЪрд╛рдп рдХреА рджреБрдХрд╛рди рд╕реЗ рднреА рдЬреНрдпрд╛рджрд╛ рд╣реИ! ЁЯШД рд▓реЗрдХрд┐рди рдпрд╣реА рджреВрд░реА рд╣рдорд╛рд░реЗ рд▓рд┐рдП рдПрдХрджрдо рд╕рд╣реА рд╣реИред"

        рдпреВрдЬрд╝рд░ рдХрд╛ рдкреНрд░рд╢реНрди/рд╕рдВрджреЗрд╢: "{text}"
        """
        
        # Generate response with optimized parameters
        response = model.generate_content(prompt, generation_config={
            'temperature': 0.6,  # Balance between creativity and accuracy
            'top_p': 0.95,
            'top_k': 40,
            'max_output_tokens': 250,
            'candidate_count': 1,
        })
        
        # Clean and format response
        response_text = response.text.strip()
        
        # Remove any English/Roman text if present, but keep emojis
        hindi_only = ''.join(char for char in response_text 
                           if ord(char) > 127 
                           or char in [' ', 'ред', '?', '!', ',', '.', '-', '\n', 'ЁЯШД', 'ЁЯШК', 'ЁЯШГ', 'ЁЯШЕ', 'ЁЯМЯ', 'ЁЯТб', 'тЬи'])
        
        # If no Hindi text was generated
        if not hindi_only.strip():
            return "рдЕрд░реЗ рд╡рд╛рд╣! рдЖрдкрдХрд╛ рд╕рд╡рд╛рд▓ рдмрдбрд╝рд╛ рджрд┐рд▓рдЪрд╕реНрдк рд╣реИред рдХреГрдкрдпрд╛ рдЗрд╕реЗ рдереЛрдбрд╝рд╛ рдФрд░ рд╕реНрдкрд╖реНрдЯ рдХрд░реЗрдВ, рддрд╛рдХрд┐ рдореИрдВ рдмреЗрд╣рддрд░ рдЬрд╡рд╛рдм рджреЗ рд╕рдХреВрдВред ЁЯШК"
            
        return hindi_only.strip()

    except Exception as e:
        print(f"AI Error: {e}")
        return "рдУрд╣! рдореЗрд░реЗ рджрд┐рдорд╛рдЧ рдореЗрдВ рдереЛрдбрд╝реА рдЦрд░рд╛рдмреА рдЖ рдЧрдИ рд╣реИред рдХреГрдкрдпрд╛ рдереЛрдбрд╝реА рджреЗрд░ рдмрд╛рдж рдлрд┐рд░ рд╕реЗ рдкреВрдЫреЗрдВред рддрдм рддрдХ рдПрдХ рдЪрд╛рдп рдХрд╛ рдЖрдирдВрдж рд▓реЗрдВ! ЁЯШД"

async def generate_audio(text, output_path):
    try:
        url = f"https://api.elevenlabs.io/v1/text-to-speech/oPM3trUCF4e0vTcsrMQr"
        headers = {
            'Accept': 'audio/mpeg',
            'Content-Type': 'application/json',
            'xi-api-key': ELEVENLABS_API_KEY
        }
        data = {
            'text': text,
            'model_id': 'eleven_multilingual_v2',
            'voice_settings': {
                'stability': 0.8,
                'similarity_boost': 0.8,
                'style': 0.7,
                'use_speaker_boost': True
            }
        }
        
        response = requests.post(url, headers=headers, json=data)
        if response.status_code == 200:
            with open(output_path, 'wb') as f:
                f.write(response.content)
            return True
        else:
            print(f"ElevenLabs API Error: {response.text}")
            return False
    except Exception as e:
        print(f"Audio generation error: {e}")
        return False

async def convert_voice_to_text(file_path):
    try:
        # Convert to WAV with better quality
        audio = AudioSegment.from_ogg(file_path)
        audio = audio.set_channels(1)  # Convert to mono
        audio = audio.set_frame_rate(16000)  # Set sample rate
        wav_path = file_path.replace('.ogg', '.wav')
        audio.export(wav_path, format="wav", parameters=["-q:a", "0"])

        # Initialize recognizer with noise handling
        recognizer = sr.Recognizer()
        recognizer.dynamic_energy_threshold = True
        recognizer.energy_threshold = 300
        
        # Convert speech to text with better accuracy
        with sr.AudioFile(wav_path) as source:
            # Adjust for ambient noise
            recognizer.adjust_for_ambient_noise(source)
            audio_data = recognizer.record(source)
            
            # Try multiple language models for better accuracy
            try:
                text = recognizer.recognize_google(audio_data, language='hi-IN')
            except:
                # Fallback to English if Hindi fails (for mixed language)
                text = recognizer.recognize_google(audio_data, language='en-IN')
            
        # Clean up
        os.remove(wav_path)
        
        return {'success': True, 'text': text}
    except Exception as e:
        print(f"Voice processing error: {e}")
        return {
            'success': False,
            'text': "рдЖрдкрдХреА рдЖрд╡рд╛рдЬрд╝ рд╕реНрдкрд╖реНрдЯ рдирд╣реАрдВ рд╣реИред рдХреГрдкрдпрд╛ рдзреАрд░реЗ рдФрд░ рд╕реНрдкрд╖реНрдЯ рд░реВрдк рд╕реЗ рдмреЛрд▓реЗрдВ рдпрд╛ рдЕрдкрдирд╛ рдкреНрд░рд╢реНрди рдЯреЗрдХреНрд╕реНрдЯ рдХреЗ рд░реВрдк рдореЗрдВ рд▓рд┐рдЦреЗрдВред"
        }

async def handle_message(update: Update, context):
    try:
        chat_id = update.message.chat_id
        
        if update.message.voice:
            # Send processing message
            processing_msg = await update.message.reply_text("ЁЯОЩя╕П рдЖрд╡рд╛рдЬрд╝ рдХреЛ рд╕рдордЭ рд░рд╣рд╛ рд╣реВрдВ...")
            
            # Download voice message
            voice = await update.message.voice.get_file()
            voice_path = os.path.join(TEMP_DIR, f"voice_{int(time.time())}.ogg")
            await voice.download_to_drive(voice_path)
            
            # Convert voice to text
            voice_result = await convert_voice_to_text(voice_path)
            os.remove(voice_path)
            
            # Delete processing message
            await processing_msg.delete()
            
            if not voice_result['success']:
                error_audio_path = os.path.join(TEMP_DIR, f"error_{int(time.time())}.mp3")
                gen_msg = await update.message.reply_text("ЁЯФК рдЖрд╡рд╛рдЬрд╝ рддреИрдпрд╛рд░ рдХрд░ рд░рд╣рд╛ рд╣реВрдВ...")
                await generate_audio(voice_result['text'], error_audio_path)
                with open(error_audio_path, 'rb') as audio:
                    await update.message.reply_voice(audio)
                os.remove(error_audio_path)
                await gen_msg.delete()
                return
                
            user_text = voice_result['text']
        elif update.message.text and not update.message.text.startswith('/'):
            user_text = update.message.text
            print(f"Received text message: {user_text}")  # Debug log
        else:
            return

        # Show AI thinking message
        thinking_msg = await update.message.reply_text("ЁЯдФ рдЖрдкрдХреЗ рд╕рд╡рд╛рд▓ рдХрд╛ рдЬрд╡рд╛рдм рддреИрдпрд╛рд░ рдХрд░ рд░рд╣рд╛ рд╣реВрдВ...")
        
        # Get AI response
        print(f"Sending to AI: {user_text}")  # Debug log
        ai_text = await generate_hindi_response(user_text)
        print(f"AI Response: {ai_text}")  # Debug log
        
        # Show generating audio message
        gen_msg = await update.message.reply_text("ЁЯФК рдЖрд╡рд╛рдЬрд╝ рддреИрдпрд╛рд░ рдХрд░ рд░рд╣рд╛ рд╣реВрдВ...")
        
        # Delete thinking message
        await thinking_msg.delete()
        
        # Generate audio response
        audio_path = os.path.join(TEMP_DIR, f"response_{int(time.time())}.mp3")
        audio_generated = await generate_audio(ai_text, audio_path)
        
        # Delete generating message
        await gen_msg.delete()
        
        # Send only voice response
        if audio_generated:
            with open(audio_path, 'rb') as audio:
                await update.message.reply_voice(audio)
            os.remove(audio_path)
        else:
            error_msg = "рдорд╛рдлрд╝ рдХреАрдЬрд┐рдпреЗ, рдЖрд╡рд╛рдЬрд╝ рдмрдирд╛рдиреЗ рдореЗрдВ рд╕рдорд╕реНрдпрд╛ рдЖрдИ рд╣реИред"
            error_audio_path = os.path.join(TEMP_DIR, f"error_{int(time.time())}.mp3")
            gen_error_msg = await update.message.reply_text("ЁЯФК рддреНрд░реБрдЯрд┐ рд╕рдВрджреЗрд╢ рддреИрдпрд╛рд░ рдХрд░ рд░рд╣рд╛ рд╣реВрдВ...")
            await generate_audio(error_msg, error_audio_path)
            with open(error_audio_path, 'rb') as audio:
                await update.message.reply_voice(audio)
            os.remove(error_audio_path)
            await gen_error_msg.delete()

    except Exception as e:
        print(f"Error: {e}")
        error_msg = "рдХреБрдЫ рддрдХрдиреАрдХреА рд╕рдорд╕реНрдпрд╛ рдЖрдИ рд╣реИред рдХреГрдкрдпрд╛ рдлрд┐рд░ рд╕реЗ рдХреЛрд╢рд┐рд╢ рдХрд░реЗрдВред"
        error_audio_path = os.path.join(TEMP_DIR, f"error_{int(time.time())}.mp3")
        gen_error_msg = await update.message.reply_text("ЁЯФК рддреНрд░реБрдЯрд┐ рд╕рдВрджреЗрд╢ рддреИрдпрд╛рд░ рдХрд░ рд░рд╣рд╛ рд╣реВрдВ...")
        await generate_audio(error_msg, error_audio_path)
        with open(error_audio_path, 'rb') as audio:
            await update.message.reply_voice(audio)
        os.remove(error_audio_path)
        await gen_error_msg.delete()

def main():
    # Create the Application
    application = Application.builder().token(TELEGRAM_TOKEN).build()
    
    # Add handlers
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT | filters.VOICE, handle_message))
    
    # Start the bot
    print("Bot is running...")
    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == '__main__':
    main() 