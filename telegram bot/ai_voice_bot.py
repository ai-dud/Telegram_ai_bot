import os
import tempfile
import time
from datetime import datetime
import speech_recognition as sr
from pydub import AudioSegment
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters
import google.generativeai as genai
import requests
from dotenv import load_dotenv

# Load environment variables
load_dotenv()
TELEGRAM_TOKEN = os.getenv('TELEGRAM_TOKEN')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
ELEVENLABS_API_KEY = os.getenv('ELEVENLABS_API_KEY')

# Initialize Gemini AI
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-pro')

# Create temp directory
TEMP_DIR = "temp"
if not os.path.exists(TEMP_DIR):
    os.makedirs(TEMP_DIR)

async def start(update: Update, context):
    welcome_message = """
ü§ñ *AI Voice Bot ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à!*
‡§Æ‡•Å‡§ù‡•á ‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§∏‡§µ‡§æ‡§≤ ‡§™‡•Ç‡§õ‡•á‡§Ç, ‡§Æ‡•à‡§Ç ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•Ç‡§Ç‡§ó‡§æ‡•§
    """
    await update.message.reply_text(welcome_message, parse_mode='Markdown')

async def generate_hindi_response(text):
    try:
        prompt = f"""
        ‡§Ü‡§™ ‡§è‡§ï ‡§¨‡§π‡•Å‡§§ ‡§π‡•Ä ‡§ï‡•Å‡§∂‡§≤ ‡§î‡§∞ ‡§Æ‡§ú‡§º‡•á‡§¶‡§æ‡§∞ AI ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§π‡•à‡§Ç‡•§ ‡§Ø‡•Ç‡§ú‡§º‡§∞ ‡§ï‡•á ‡§∏‡§µ‡§æ‡§≤ ‡§ï‡§æ ‡§ú‡§µ‡§æ‡§¨ ‡§á‡§® ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡•ã‡§Ç ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§¶‡•á‡§Ç:

        1. ‡§ú‡§µ‡§æ‡§¨ ‡§ï‡•Ä ‡§µ‡§ø‡§∂‡•á‡§∑‡§§‡§æ‡§è‡§Ç:
           - ‡§¨‡§ø‡§≤‡•ç‡§ï‡•Å‡§≤ ‡§∏‡§ü‡•Ä‡§ï ‡§î‡§∞ ‡§§‡§•‡•ç‡§Ø‡§æ‡§§‡•ç‡§Æ‡§ï ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§¶‡•á‡§Ç
           - ‡§∏‡§∞‡§≤ ‡§î‡§∞ ‡§∞‡•ã‡§ö‡§ï ‡§≠‡§æ‡§∑‡§æ ‡§ï‡§æ ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç
           - ‡§π‡§∞ ‡§ú‡§µ‡§æ‡§¨ ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§Æ‡§ú‡§º‡•á‡§¶‡§æ‡§∞ ‡§ü‡§ø‡§™‡•ç‡§™‡§£‡•Ä ‡§Ø‡§æ ‡§â‡§¶‡§æ‡§π‡§∞‡§£ ‡§ú‡•ã‡§°‡§º‡•á‡§Ç
           - ‡§ú‡§µ‡§æ‡§¨ ‡§ï‡•ã ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§ ‡§≤‡•á‡§ï‡§ø‡§® ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§∞‡§ñ‡•á‡§Ç (40-50 ‡§∂‡§¨‡•ç‡§¶)

        2. ‡§ú‡§µ‡§æ‡§¨ ‡§ï‡§æ ‡§™‡•ç‡§∞‡§æ‡§∞‡•Ç‡§™:
           - ‡§™‡§π‡§≤‡•á ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§¶‡•á‡§Ç
           - ‡§´‡§ø‡§∞ ‡§è‡§ï ‡§Æ‡§ú‡§º‡•á‡§¶‡§æ‡§∞ ‡§ü‡§ø‡§™‡•ç‡§™‡§£‡•Ä ‡§Ø‡§æ ‡§â‡§¶‡§æ‡§π‡§∞‡§£
           - ‡§Ö‡§Ç‡§§ ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§õ‡•ã‡§ü‡•Ä ‡§∏‡•Ä ‡§∏‡§≤‡§æ‡§π ‡§Ø‡§æ ‡§®‡§ø‡§∑‡•ç‡§ï‡§∞‡•ç‡§∑

        3. ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§ß‡•ç‡§Ø‡§æ‡§®:
           - ‡§π‡§∞ ‡§ú‡§µ‡§æ‡§¨ 100% ‡§∏‡§ü‡•Ä‡§ï ‡§π‡•ã‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è
           - ‡§ú‡§µ‡§æ‡§¨ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§π‡•Ä ‡§¶‡•á‡§Ç
           - ‡§ú‡§ü‡§ø‡§≤ ‡§µ‡§ø‡§∑‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§≠‡•Ä ‡§∏‡§∞‡§≤ ‡§¨‡§®‡§æ‡§ï‡§∞ ‡§∏‡§Æ‡§ù‡§æ‡§è‡§Ç
           - ‡§Ø‡§¶‡§ø ‡§ï‡•ã‡§à ‡§¨‡§æ‡§§ ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à, ‡§§‡•ã ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü‡•Ä‡§ï‡§∞‡§£ ‡§Æ‡§æ‡§Ç‡§ó‡•á‡§Ç

        ‡§â‡§¶‡§æ‡§π‡§∞‡§£ ‡§ú‡§µ‡§æ‡§¨:
        "‡§∏‡•Ç‡§∞‡•ç‡§Ø ‡§∏‡•á ‡§™‡•É‡§•‡•ç‡§µ‡•Ä ‡§ï‡•Ä ‡§¶‡•Ç‡§∞‡•Ä 15 ‡§ï‡§∞‡•ã‡§°‡§º ‡§ï‡§ø‡§≤‡•ã‡§Æ‡•Ä‡§ü‡§∞ ‡§π‡•à‡•§ ‡§á‡§§‡§®‡•Ä ‡§¶‡•Ç‡§∞‡•Ä ‡§§‡•ã ‡§Æ‡•á‡§∞‡•á ‡§™‡§°‡§º‡•ã‡§∏‡•Ä ‡§ï‡•Ä ‡§ö‡§æ‡§Ø ‡§ï‡•Ä ‡§¶‡•Å‡§ï‡§æ‡§® ‡§∏‡•á ‡§≠‡•Ä ‡§ú‡•ç‡§Ø‡§æ‡§¶‡§æ ‡§π‡•à! üòÑ ‡§≤‡•á‡§ï‡§ø‡§® ‡§Ø‡§π‡•Ä ‡§¶‡•Ç‡§∞‡•Ä ‡§π‡§Æ‡§æ‡§∞‡•á ‡§≤‡§ø‡§è ‡§è‡§ï‡§¶‡§Æ ‡§∏‡§π‡•Ä ‡§π‡•à‡•§"

        ‡§Ø‡•Ç‡§ú‡§º‡§∞ ‡§ï‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®/‡§∏‡§Ç‡§¶‡•á‡§∂: "{text}"
        """
        
        # Generate response with optimized parameters
        response = model.generate_content(prompt, generation_config={
            'temperature': 0.6,  # Balance between creativity and accuracy
            'top_p': 0.95,
            'top_k': 40,
            'max_output_tokens': 250,
            'candidate_count': 1,
        })
        
        # Clean and format response
        response_text = response.text.strip()
        
        # Remove any English/Roman text if present, but keep emojis
        hindi_only = ''.join(char for char in response_text 
                           if ord(char) > 127 
                           or char in [' ', '‡•§', '?', '!', ',', '.', '-', '\n', 'üòÑ', 'üòä', 'üòÉ', 'üòÖ', 'üåü', 'üí°', '‚ú®'])
        
        # If no Hindi text was generated
        if not hindi_only.strip():
            return "‡§Ö‡§∞‡•á ‡§µ‡§æ‡§π! ‡§Ü‡§™‡§ï‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§¨‡§°‡§º‡§æ ‡§¶‡§ø‡§≤‡§ö‡§∏‡•ç‡§™ ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§á‡§∏‡•á ‡§•‡•ã‡§°‡§º‡§æ ‡§î‡§∞ ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§ï‡§∞‡•á‡§Ç, ‡§§‡§æ‡§ï‡§ø ‡§Æ‡•à‡§Ç ‡§¨‡•á‡§π‡§§‡§∞ ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á ‡§∏‡§ï‡•Ç‡§Ç‡•§ üòä"
            
        return hindi_only.strip()

    except Exception as e:
        print(f"AI Error: {e}")
        return "‡§ì‡§π! ‡§Æ‡•á‡§∞‡•á ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§Æ‡•á‡§Ç ‡§•‡•ã‡§°‡§º‡•Ä ‡§ñ‡§∞‡§æ‡§¨‡•Ä ‡§Ü ‡§ó‡§à ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§•‡•ã‡§°‡§º‡•Ä ‡§¶‡•á‡§∞ ‡§¨‡§æ‡§¶ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§™‡•Ç‡§õ‡•á‡§Ç‡•§ ‡§§‡§¨ ‡§§‡§ï ‡§è‡§ï ‡§ö‡§æ‡§Ø ‡§ï‡§æ ‡§Ü‡§®‡§Ç‡§¶ ‡§≤‡•á‡§Ç! üòÑ"

async def generate_audio(text, output_path):
    try:
        url = f"https://api.elevenlabs.io/v1/text-to-speech/oPM3trUCF4e0vTcsrMQr"
        headers = {
            'Accept': 'audio/mpeg',
            'Content-Type': 'application/json',
            'xi-api-key': ELEVENLABS_API_KEY
        }
        data = {
            'text': text,
            'model_id': 'eleven_multilingual_v2',
            'voice_settings': {
                'stability': 0.8,
                'similarity_boost': 0.8,
                'style': 0.7,
                'use_speaker_boost': True
            }
        }
        
        response = requests.post(url, headers=headers, json=data)
        if response.status_code == 200:
            with open(output_path, 'wb') as f:
                f.write(response.content)
            return True
        else:
            print(f"ElevenLabs API Error: {response.text}")
            return False
    except Exception as e:
        print(f"Audio generation error: {e}")
        return False

async def convert_voice_to_text(file_path):
    try:
        # Convert to WAV with better quality
        audio = AudioSegment.from_ogg(file_path)
        audio = audio.set_channels(1)  # Convert to mono
        audio = audio.set_frame_rate(16000)  # Set sample rate
        wav_path = file_path.replace('.ogg', '.wav')
        audio.export(wav_path, format="wav", parameters=["-q:a", "0"])

        # Initialize recognizer with noise handling
        recognizer = sr.Recognizer()
        recognizer.dynamic_energy_threshold = True
        recognizer.energy_threshold = 300
        
        # Convert speech to text with better accuracy
        with sr.AudioFile(wav_path) as source:
            # Adjust for ambient noise
            recognizer.adjust_for_ambient_noise(source)
            audio_data = recognizer.record(source)
            
            # Try multiple language models for better accuracy
            try:
                text = recognizer.recognize_google(audio_data, language='hi-IN')
            except:
                # Fallback to English if Hindi fails (for mixed language)
                text = recognizer.recognize_google(audio_data, language='en-IN')
            
        # Clean up
        os.remove(wav_path)
        
        return {'success': True, 'text': text}
    except Exception as e:
        print(f"Voice processing error: {e}")
        return {
            'success': False,
            'text': "‡§Ü‡§™‡§ï‡•Ä ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§ß‡•Ä‡§∞‡•á ‡§î‡§∞ ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§¨‡•ã‡§≤‡•á‡§Ç ‡§Ø‡§æ ‡§Ö‡§™‡§®‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§≤‡§ø‡§ñ‡•á‡§Ç‡•§"
        }

async def handle_message(update: Update, context):
    try:
        chat_id = update.message.chat_id
        
        if update.message.voice:
            # Send processing message
            processing_msg = await update.message.reply_text("üéôÔ∏è ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§ï‡•ã ‡§∏‡§Æ‡§ù ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç...")
            
            # Download voice message
            voice = await update.message.voice.get_file()
            voice_path = os.path.join(TEMP_DIR, f"voice_{int(time.time())}.ogg")
            await voice.download_to_drive(voice_path)
            
            # Convert voice to text
            voice_result = await convert_voice_to_text(voice_path)
            os.remove(voice_path)
            
            # Delete processing message
            await processing_msg.delete()
            
            if not voice_result['success']:
                error_audio_path = os.path.join(TEMP_DIR, f"error_{int(time.time())}.mp3")
                gen_msg = await update.message.reply_text("üîä ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç...")
                await generate_audio(voice_result['text'], error_audio_path)
                with open(error_audio_path, 'rb') as audio:
                    await update.message.reply_voice(audio)
                os.remove(error_audio_path)
                await gen_msg.delete()
                return
                
            user_text = voice_result['text']
        elif update.message.text and not update.message.text.startswith('/'):
            user_text = update.message.text
            print(f"Received text message: {user_text}")  # Debug log
        else:
            return

        # Show AI thinking message
        thinking_msg = await update.message.reply_text("ü§î ‡§Ü‡§™‡§ï‡•á ‡§∏‡§µ‡§æ‡§≤ ‡§ï‡§æ ‡§ú‡§µ‡§æ‡§¨ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç...")
        
        # Get AI response
        print(f"Sending to AI: {user_text}")  # Debug log
        ai_text = await generate_hindi_response(user_text)
        print(f"AI Response: {ai_text}")  # Debug log
        
        # Show generating audio message
        gen_msg = await update.message.reply_text("üîä ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç...")
        
        # Delete thinking message
        await thinking_msg.delete()
        
        # Generate audio response
        audio_path = os.path.join(TEMP_DIR, f"response_{int(time.time())}.mp3")
        audio_generated = await generate_audio(ai_text, audio_path)
        
        # Delete generating message
        await gen_msg.delete()
        
        # Send only voice response
        if audio_generated:
            with open(audio_path, 'rb') as audio:
                await update.message.reply_voice(audio)
            os.remove(audio_path)
        else:
            error_msg = "‡§Æ‡§æ‡§´‡§º ‡§ï‡•Ä‡§ú‡§ø‡§Ø‡•á, ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§¨‡§®‡§æ‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§Ü‡§à ‡§π‡•à‡•§"
            error_audio_path = os.path.join(TEMP_DIR, f"error_{int(time.time())}.mp3")
            gen_error_msg = await update.message.reply_text("üîä ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø ‡§∏‡§Ç‡§¶‡•á‡§∂ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç...")
            await generate_audio(error_msg, error_audio_path)
            with open(error_audio_path, 'rb') as audio:
                await update.message.reply_voice(audio)
            os.remove(error_audio_path)
            await gen_error_msg.delete()

    except Exception as e:
        print(f"Error: {e}")
        error_msg = "‡§ï‡•Å‡§õ ‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§Ü‡§à ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§"
        error_audio_path = os.path.join(TEMP_DIR, f"error_{int(time.time())}.mp3")
        gen_error_msg = await update.message.reply_text("üîä ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø ‡§∏‡§Ç‡§¶‡•á‡§∂ ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç...")
        await generate_audio(error_msg, error_audio_path)
        with open(error_audio_path, 'rb') as audio:
            await update.message.reply_voice(audio)
        os.remove(error_audio_path)
        await gen_error_msg.delete()

def main():
    # Create the Application
    application = Application.builder().token(TELEGRAM_TOKEN).build()
    
    # Add handlers
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT | filters.VOICE, handle_message))
    
    # Start the bot
    print("Bot is running...")
    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == '__main__':
    main() 